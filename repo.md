
PS C:\Development> ollama serve
time=2025-11-28T12:52:39.453-05:00 level=INFO source=routes.go:1544 msg="server config" env="map[CUDA_VISIBLE_DEVICES: GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:C:\\Users\\Anthony\\.ollama\\models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false OLLAMA_VULKAN:false ROCR_VISIBLE_DEVICES:]"
time=2025-11-28T12:52:39.455-05:00 level=INFO source=images.go:522 msg="total blobs: 0"
time=2025-11-28T12:52:39.455-05:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-28T12:52:39.456-05:00 level=INFO source=routes.go:1597 msg="Listening on 127.0.0.1:11434 (version 0.13.0)"
time=2025-11-28T12:52:39.458-05:00 level=INFO source=runner.go:67 msg="discovering available GPUs..."
time=2025-11-28T12:52:39.478-05:00 level=INFO source=server.go:392 msg="starting runner" cmd="C:\\Users\\Anthony\\AppData\\Local\\Programs\\Ollama\\ollama.exe runner --ollama-engine --port 11939"
time=2025-11-28T12:52:39.868-05:00 level=INFO source=server.go:392 msg="starting runner" cmd="C:\\Users\\Anthony\\AppData\\Local\\Programs\\Ollama\\ollama.exe runner --ollama-engine --port 11951"
time=2025-11-28T12:52:40.974-05:00 level=INFO source=server.go:392 msg="starting runner" cmd="C:\\Users\\Anthony\\AppData\\Local\\Programs\\Ollama\\ollama.exe runner --ollama-engine --port 11958"
time=2025-11-28T12:52:41.373-05:00 level=INFO source=runner.go:102 msg="experimental Vulkan support disabled.  To enable, set OLLAMA_VULKAN=1"
time=2025-11-28T12:52:41.373-05:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-1ffebd1a-a66a-d662-6afb-369cd55a17be filter_id="" library=CUDA compute=8.6 name=CUDA1 description="NVIDIA GeForce RTX 3090" libdirs=ollama,cuda_v12 driver=13.0 pci_id=0000:0c:00.0 type=discrete total="24.0 GiB" available="8.5 GiB"
time=2025-11-28T12:52:41.373-05:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-edc917ac-1775-0a79-3b7c-6eccff36fe05 filter_id="" library=CUDA compute=8.6 name=CUDA0 description="NVIDIA GeForce RTX 3090" libdirs=ollama,cuda_v12 driver=13.0 pci_id=0000:0b:00.0 type=discrete total="24.0 GiB" available="8.3 GiB"
[GIN] 2025/11/28 - 12:52:49 | 404 |       503.3Âµs |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/28 - 12:53:02 | 200 |            0s |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/28 - 12:53:02 | 200 |            0s |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 12:53:08 | 200 |            0s |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/28 - 12:53:08 | 200 |            0s |       127.0.0.1 | GET      "/api/ps"
[GIN] 2025/11/28 - 12:53:31 | 200 |            0s |       127.0.0.1 | HEAD     "/"
time=2025-11-28T12:53:32.421-05:00 level=INFO source=download.go:177 msg="downloading 3291abe70f16 in 21 1 GB part(s)"
[GIN] 2025/11/28 - 12:54:34 | 200 |            0s |       127.0.0.1 | GET      "/api/version"
[GIN] 2025/11/28 - 12:54:34 | 200 |      1.0602ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 12:54:34 | 404 |      1.0602ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/28 - 12:55:04 | 200 |         683Âµs |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 12:55:34 | 200 |       731.7Âµs |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 12:55:40 | 200 |            0s |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/28 - 12:55:40 | 200 |            0s |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 12:55:53 | 200 |            0s |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/28 - 12:55:53 | 200 |            0s |       127.0.0.1 | GET      "/api/ps"
[GIN] 2025/11/28 - 12:56:03 | 200 |            0s |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/28 - 12:56:03 | 200 |    226.8323ms |       127.0.0.1 | POST     "/api/me"
[GIN] 2025/11/28 - 12:56:04 | 200 |       634.5Âµs |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 12:56:34 | 200 |            0s |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 12:57:04 | 200 |            0s |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 12:57:34 | 200 |            0s |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 12:58:04 | 200 |       557.2Âµs |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 12:58:34 | 200 |         513Âµs |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 12:59:04 | 200 |       516.7Âµs |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 12:59:14 | 200 |            0s |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/28 - 12:59:15 | 404 |      1.0249ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/28 - 12:59:34 | 200 |      1.0724ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:00:04 | 200 |       551.6Âµs |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:00:34 | 200 |         794Âµs |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:01:15 | 200 |       532.6Âµs |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:01:45 | 200 |       519.7Âµs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-28T13:02:14.212-05:00 level=INFO source=download.go:177 msg="downloading ae370d884f10 in 1 1.7 KB part(s)"
[GIN] 2025/11/28 - 13:02:15 | 200 |       706.4Âµs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-28T13:02:15.393-05:00 level=INFO source=download.go:177 msg="downloading d18a5cc71b84 in 1 11 KB part(s)"
time=2025-11-28T13:02:16.644-05:00 level=INFO source=download.go:177 msg="downloading cff3f395ef37 in 1 120 B part(s)"
time=2025-11-28T13:02:17.845-05:00 level=INFO source=download.go:177 msg="downloading afdf5c7585b3 in 1 488 B part(s)"
[GIN] 2025/11/28 - 13:02:45 | 200 |       516.8Âµs |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:03:15 | 200 |            0s |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:03:18 | 200 |          4m3s |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/11/28 - 13:03:18 | 200 |         9m46s |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/11/28 - 13:03:18 | 200 |     68.2744ms |       127.0.0.1 | POST     "/api/show"
time=2025-11-28T13:03:18.766-05:00 level=INFO source=server.go:392 msg="starting runner" cmd="C:\\Users\\Anthony\\AppData\\Local\\Programs\\Ollama\\ollama.exe runner --ollama-engine --port 12851"
time=2025-11-28T13:03:19.234-05:00 level=INFO source=cpu_windows.go:148 msg=packages count=1
time=2025-11-28T13:03:19.234-05:00 level=INFO source=cpu_windows.go:195 msg="" package=0 cores=8 efficiency=0 threads=16
time=2025-11-28T13:03:19.316-05:00 level=INFO source=server.go:209 msg="enabling flash attention"
time=2025-11-28T13:03:19.318-05:00 level=INFO source=server.go:392 msg="starting runner" cmd="C:\\Users\\Anthony\\AppData\\Local\\Programs\\Ollama\\ollama.exe runner --ollama-engine --model C:\\Users\\Anthony\\.ollama\\models\\blobs\\sha256-3291abe70f16ee9682de7bfae08db5373ea9d6497e614aaad63340ad421d6312 --port 11217"
time=2025-11-28T13:03:19.321-05:00 level=INFO source=sched.go:443 msg="system memory" total="63.9 GiB" free="44.7 GiB" free_swap="53.1 GiB"
time=2025-11-28T13:03:19.321-05:00 level=INFO source=sched.go:450 msg="gpu memory" id=GPU-edc917ac-1775-0a79-3b7c-6eccff36fe05 library=CUDA available="22.5 GiB" free="22.9 GiB" minimum="457.0 MiB" overhead="0 B"
time=2025-11-28T13:03:19.321-05:00 level=INFO source=sched.go:450 msg="gpu memory" id=GPU-1ffebd1a-a66a-d662-6afb-369cd55a17be library=CUDA available="23.1 GiB" free="23.5 GiB" minimum="457.0 MiB" overhead="0 B"
time=2025-11-28T13:03:19.321-05:00 level=INFO source=server.go:702 msg="loading model" "model layers"=65 requested=-1
time=2025-11-28T13:03:19.402-05:00 level=INFO source=runner.go:1398 msg="starting ollama engine"
time=2025-11-28T13:03:19.403-05:00 level=INFO source=runner.go:1433 msg="Server listening on 127.0.0.1:11217"
time=2025-11-28T13:03:19.410-05:00 level=INFO source=runner.go:1271 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:65[ID:GPU-1ffebd1a-a66a-d662-6afb-369cd55a17be Layers:65(0..64)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-28T13:03:19.438-05:00 level=INFO source=ggml.go:136 msg="" architecture=qwen3 file_type=Q4_K_M name="Qwen3 32B" description="" num_tensors=707 num_key_values=28
load_backend: loaded CPU backend from C:\Users\Anthony\AppData\Local\Programs\Ollama\lib\ollama\ggml-cpu-haswell.dll
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 2 CUDA devices:
  Device 0: NVIDIA GeForce RTX 3090, compute capability 8.6, VMM: yes, ID: GPU-edc917ac-1775-0a79-3b7c-6eccff36fe05
  Device 1: NVIDIA GeForce RTX 3090, compute capability 8.6, VMM: yes, ID: GPU-1ffebd1a-a66a-d662-6afb-369cd55a17be
load_backend: loaded CUDA backend from C:\Users\Anthony\AppData\Local\Programs\Ollama\lib\ollama\cuda_v12\ggml-cuda.dll
time=2025-11-28T13:03:19.603-05:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=500,520,600,610,700,750,800,860,890,900,1200 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 CUDA.1.ARCHS=500,520,600,610,700,750,800,860,890,900,1200 CUDA.1.USE_GRAPHS=1 CUDA.1.PEER_MAX_BATCH_SIZE=128 compiler=cgo(clang)
time=2025-11-28T13:03:19.838-05:00 level=INFO source=runner.go:1271 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:65[ID:GPU-1ffebd1a-a66a-d662-6afb-369cd55a17be Layers:65(0..64)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-28T13:03:20.473-05:00 level=INFO source=runner.go:1271 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:65[ID:GPU-1ffebd1a-a66a-d662-6afb-369cd55a17be Layers:65(0..64)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-28T13:03:20.474-05:00 level=INFO source=ggml.go:482 msg="offloading 64 repeating layers to GPU"
time=2025-11-28T13:03:20.474-05:00 level=INFO source=ggml.go:489 msg="offloading output layer to GPU"
time=2025-11-28T13:03:20.474-05:00 level=INFO source=ggml.go:494 msg="offloaded 65/65 layers to GPU"
time=2025-11-28T13:03:20.474-05:00 level=INFO source=device.go:240 msg="model weights" device=CUDA1 size="18.4 GiB"
time=2025-11-28T13:03:20.474-05:00 level=INFO source=device.go:245 msg="model weights" device=CPU size="417.3 MiB"
time=2025-11-28T13:03:20.474-05:00 level=INFO source=device.go:251 msg="kv cache" device=CUDA1 size="1.0 GiB"
time=2025-11-28T13:03:20.474-05:00 level=INFO source=device.go:262 msg="compute graph" device=CUDA1 size="330.0 MiB"
time=2025-11-28T13:03:20.474-05:00 level=INFO source=device.go:267 msg="compute graph" device=CPU size="10.0 MiB"
time=2025-11-28T13:03:20.474-05:00 level=INFO source=device.go:272 msg="total memory" size="20.1 GiB"
time=2025-11-28T13:03:20.474-05:00 level=INFO source=sched.go:517 msg="loaded runners" count=1
time=2025-11-28T13:03:20.474-05:00 level=INFO source=server.go:1294 msg="waiting for llama runner to start responding"
time=2025-11-28T13:03:20.475-05:00 level=INFO source=server.go:1328 msg="waiting for server to become available" status="llm server loading model"
time=2025-11-28T13:03:25.489-05:00 level=INFO source=server.go:1332 msg="llama runner started in 6.17 seconds"
[GIN] 2025/11/28 - 13:03:29 | 200 |   10.8935706s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/28 - 13:03:45 | 200 |      1.1307ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:04:15 | 200 |        1.24ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:04:45 | 200 |       1.187ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:05:15 | 200 |      1.0213ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:05:45 | 200 |      1.0334ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:06:15 | 200 |      1.1067ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:06:45 | 200 |      1.0289ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:07:15 | 200 |      1.0258ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:07:45 | 200 |      1.1561ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:08:15 | 200 |      1.2561ms |       127.0.0.1 | GET      "/api/tags"
ggml_backend_cuda_device_get_memory device GPU-1ffebd1a-a66a-d662-6afb-369cd55a17be utilizing NVML memory reporting free: 3999965184 total: 25769803776
time=2025-11-28T13:08:29.619-05:00 level=INFO source=server.go:392 msg="starting runner" cmd="C:\\Users\\Anthony\\AppData\\Local\\Programs\\Ollama\\ollama.exe runner --ollama-engine --port 14958"
time=2025-11-28T13:08:30.282-05:00 level=INFO source=server.go:392 msg="starting runner" cmd="C:\\Users\\Anthony\\AppData\\Local\\Programs\\Ollama\\ollama.exe runner --ollama-engine --port 14970"
[GIN] 2025/11/28 - 13:08:45 | 200 |      1.0231ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:09:15 | 200 |      1.0379ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:09:45 | 200 |      2.3111ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:10:15 | 200 |      1.2699ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:10:45 | 200 |      1.7948ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:11:15 | 200 |       1.113ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:11:45 | 200 |      2.1324ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:12:15 | 200 |      1.0498ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:12:45 | 200 |      1.0554ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:13:15 | 200 |      1.1675ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:13:45 | 200 |      1.7331ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:14:15 | 200 |      1.0492ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:14:45 | 200 |      1.0828ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:15:15 | 200 |      1.0213ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:15:45 | 200 |      1.7206ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:16:15 | 200 |      1.0564ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:16:45 | 200 |      1.5393ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:17:15 | 200 |      1.0545ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:17:45 | 200 |      1.0303ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:18:15 | 200 |      1.0366ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:18:45 | 200 |      1.0187ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:19:15 | 200 |      1.0944ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:19:45 | 200 |      1.5474ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:20:15 | 200 |      1.0289ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:20:45 | 200 |      1.0203ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:21:15 | 200 |      1.5371ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:21:45 | 200 |      1.5884ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:22:15 | 200 |      1.0231ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:22:45 | 200 |      1.0221ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:23:15 | 200 |      1.0348ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:23:45 | 200 |      1.5873ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:24:15 | 200 |      1.5594ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:24:45 | 200 |      1.0493ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:25:15 | 200 |      1.0504ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:25:45 | 200 |      1.7439ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:26:15 | 200 |      1.0378ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:26:45 | 200 |      1.1565ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:27:15 | 200 |        1.56ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:27:45 | 200 |      1.0303ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:28:15 | 200 |      1.0376ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:28:45 | 200 |      1.1663ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:29:15 | 200 |      1.5836ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:29:46 | 200 |      1.5414ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:30:16 | 200 |      1.0459ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/11/28 - 13:30:46 | 200 |      1.0344ms |       127.0.0.1 | GET      "/api/tags"


PS C:\Development> curl http://192.168.86.35:11434/api/generate -d '{"model":"qwen3:32b","prompt":"Hello","stream":false }'
{"model":"qwen3:32b","created_at":"2025-11-28T18:38:23.3296641Z","response":"Hello! ðŸ˜Š How can I assist you today? Feel free to ask me anything!","thinking":"Okay, the user said \"Hello\". I need to respond appropriately. Let me start by greeting them back in a friendly manner. Maybe add an emoji to keep it warm. Then, offer assistance. I should ask how I can help them today. Keep it open-ended so they feel comfortable to ask anything. Make sure the tone is positive and welcoming. Let me put that all together concisely.\n","done":true,"done_reason":"stop","context":[151644,872,198,9707,608,26865,151645,198,151644,77091,198,151667,198,32313,11,279,1196,1053,330,9707,3263,358,1184,311,5889,34901,13,6771,752,1191,553,42113,1105,1182,304,264,11657,11566,13,10696,912,458,42365,311,2506,432,8205,13,5005,11,3010,12994,13,358,1265,2548,1246,358,646,1492,1105,3351,13,13655,432,1787,83075,773,807,2666,10655,311,2548,4113,13,7405,2704,279,16232,374,6785,323,35287,13,6771,752,2182,429,678,3786,3529,285,974,624,151668,271,9707,0,26525,232,2585,646,358,7789,498,3351,30,31733,1910,311,2548,752,4113,0],"total_duration":497339069600,"load_duration":493913370800,"prompt_eval_count":11,"prompt_eval_duration":459266600,"eval_count":104,"eval_duration":2946138600}
PS C:\Development>

